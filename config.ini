[Server]
log_file = logs/llmproxy.log
api_keys = config/api_keys.txt
port = 8000

[Backend_1]
url = http://wil-gpu-14.bluelobster.ai:10934
model = meta-llama/Meta-Llama-3.1-8B-Instruct
api_key = bl-2ny2hTassWhjy9oR7KTfZawk_um4L87UNW-opRj
queue_size = 10

[Backend_2]
url = http://wil-gpu-14.bluelobster.ai:10929
model = Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4
api_key = bl-2ny2hTassWhjy9oR7KTfZawk_um4L87UNW-opRj
queue_size = 10

[Backend_3]
url = http://wil-gpu-14.bluelobster.ai:10910
model = mistralai/Mistral-Nemo-Instruct-2407
api_key = bl-2ny2hTassWhjy9oR7KTfZawk_um4L87UNW-opRj
queue_size = 10