[Server]
port = 8000
log_file = access_log.csv

[Auth]
api_keys_file = ~/vllm_proxy_server/config/authorized_users.txt

[DefaultServer]
url = http://wil-gpu-14.bluelobster.ai:10913
model = meta-llama/Meta-Llama-3.1-8B-Instruct
queue_size = 10

[SecondaryServer]
url = http://wil-gpu-14.bluelobster.ai:10929
model = Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4
queue_size = 5
